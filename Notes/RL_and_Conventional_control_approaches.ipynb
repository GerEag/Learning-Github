{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaches for combining conventional control methods and RL\n",
    "\n",
    "## Linear control (PD) + agent action\n",
    "\n",
    "One method to combine RL and conventional control is to apply a fixed-gain feedback controller with an added term learned by the RL agent. The gains for the fixed-gain controller can be designed with some knowledge about the system. This requires either a simple system, or a simplified system.\n",
    "\n",
    "## Model-Reference Control and RL\n",
    "\n",
    "Place an RL component into a conventional model reference controller, which contains the response of a nominal reference model to a baseline controller. Can provide some local stability guarantees if the agent can maintain low error between true output and model output. The design of the baseline controller still requires some understanding of the system in order to develop the nominal model used for the reference model. There may be other combined control methods that allow for the utilization of domain knowledge without needing to really understand the system at all.\n",
    "\n",
    "### References\n",
    "\n",
    "Zhang, Qingrui, \"Model-Reference Reinforcement Learning for Collision-Free Tracking Control of Autonomous Surface Vehicles\" IEEE Transactions on Intelligent Transportation Systems (2021)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
